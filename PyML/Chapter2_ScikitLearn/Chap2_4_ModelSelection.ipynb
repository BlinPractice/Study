{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chap2_4_ModelSelection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNi7hn5nAC7UtPZOVOVO4Ye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyBlin/Study/blob/main/PyML/Chapter2_ScikitLearn/Chap2_4_ModelSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VzmAU2aT54p"
      },
      "source": [
        "# 4.Model Selection 모듈 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJON50PZYxCE"
      },
      "source": [
        "## 4.1 train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JjcT7YFY1N1",
        "outputId": "06a0eac2-ac5d-40de-d8e9-b4b9e61c2db1"
      },
      "source": [
        "# 테스트 데이터셋을 이용하지 않고 무엇이 문제인지 확인해보기\n",
        "# 한마디로 학습과 예측을 동일한 데이터셋으로 수행\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터셋으로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print(f\"예측 정확도 : {accuracy_score(train_label, pred)}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xw5yrHLZyS_"
      },
      "source": [
        "* 정확도가 100%...? 이건 그냥 컨닝한거나 다름없습니다.\n",
        "* 이제 `train_test_split()`으로 학습용과 테스트용 데이터셋을 분리해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQeBaNTLZjL9"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, \n",
        "                                                    iris_data.target, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=121)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_OncEilaxP8"
      },
      "source": [
        "* `train_test_split(피처 데이터셋, 레이블 데이터셋)`\n",
        "* `test_size` : 테스트 데이터셋 크기를 결정합니다. (default=0.25)\n",
        "* `shuffle` : 데이터 분리 전에 데이터를 섞을지 결정합니다. (default=True)\n",
        "* `random_state` : 지정하지 않으면 수행할 때마다 다른 학습용/테스트용 데이터셋을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-4s86tJanAu",
        "outputId": "f67147da-2934-4fbf-9173-cf14dfc0d4e1"
      },
      "source": [
        "# 의사결정나무를 학습하고 예측 정확도를 측정\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print(f\"예측 정확도 : {accuracy_score(y_test, pred):.4f}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 : 0.9556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSGDJBulcRes"
      },
      "source": [
        "## 4.2 교차 검증 (Cross Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnT0QmH3cQUU"
      },
      "source": [
        "### 4.2.1 K-fold 교차 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huMJ-iileF3u",
        "outputId": "0f0809c0-cfd7-44af-98cc-227db62181b4"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris_data = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# 5개의 폴드셋으로 분리하는 KFold 객체와 폴드셋별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print(f\"붓꽃 데이터셋 크기 : {features.shape[0]}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터셋 크기 : 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BneYXaClfA7o"
      },
      "source": [
        "* 전체 데이터셋 150을 5등분 하면\n",
        "    - 학습용 데이터셋 : 120개\n",
        "    - 검증용 데이터셋 : 30개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDuRDmooe577",
        "outputId": "bfbb86a5-83c9-43f3-f169-e27b7a571be9"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# split()를 호출하면 폴드별 학습용/검증용 테스트의 row index를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "\n",
        "    # kfold.split()으로 반환된 인덱스를 이용해 학습용/검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "\n",
        "    # 반복할 때마다 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print(f\"\\n#{n_iter} 교차 검증 정확도 : {accuracy}, \\\n",
        "    학습 데이터 크기 : {train_size}, \\\n",
        "    검증 데이터 크기 : {test_size}\")\n",
        "    print(f\"#{n_iter} 검증셋 인덱스 : {test_index}\")\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print(f\"\\n## 평균 검증 정확도 : {np.mean(cv_accuracy)*100:.2f} %\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 1.0,     학습 데이터 크기 : 120,     검증 데이터 크기 : 30\n",
            "#1 검증셋 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 : 1.0,     학습 데이터 크기 : 120,     검증 데이터 크기 : 30\n",
            "#2 검증셋 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.8333,     학습 데이터 크기 : 120,     검증 데이터 크기 : 30\n",
            "#3 검증셋 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 : 0.9333,     학습 데이터 크기 : 120,     검증 데이터 크기 : 30\n",
            "#4 검증셋 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 : 0.8333,     학습 데이터 크기 : 120,     검증 데이터 크기 : 30\n",
            "#5 검증셋 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도 : 92.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9yYLKu9h4Wq"
      },
      "source": [
        "### 4.2.2. Stratified K-fold\n",
        "\n",
        "* 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K-fold 방식\n",
        "* ex) 대출사기 : 0.0001% 확률로 대출 사기 레이블이 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCZz0Oa-ihsL",
        "outputId": "d56aa797-3eac-4d57-cdb4-18f3fe672f75"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk4l7baEj2Cm"
      },
      "source": [
        "* 레이블 값이 0(Setosa), 1(Versicolor), 2(Virginica) 모두 50개로 동일합니다.\n",
        "* 먼저 KFold를 사용하여 문제점을 알아봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJNK56u1jjUA",
        "outputId": "04f10857-b4fc-4113-b1b7-3afab31e7d3b"
      },
      "source": [
        "# 3개의 폴드셋을 KFold로 생성\n",
        "# 교차 검증을 할 때마다 생성되는 학습용/검증용 레이블 데이터 값의 분포도 확인\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(f\"## 교차 검증 : {n_iter}\")\n",
        "    print(f\"학습 레이블 데이터 분포 : \\n{label_train.value_counts()}\")\n",
        "    print(f\"검증 레이블 데이터 분포 : \\n{label_test.value_counts()}\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증 : 1\n",
            "학습 레이블 데이터 분포 : \n",
            "2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "\n",
            "## 교차 검증 : 2\n",
            "학습 레이블 데이터 분포 : \n",
            "2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "\n",
            "## 교차 검증 : 3\n",
            "학습 레이블 데이터 분포 : \n",
            "1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR1vgSJwlZiG"
      },
      "source": [
        "* 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었습니다.\n",
        "    - 학습한 데이터를 바탕으로 검증해야하는데, 생뚱맞은 값이 나왔습니다.\n",
        "    - 이렇게 하면 검증 예측 정확도는 0% 입니다 ㅠㅠ\n",
        "\n",
        "* Stratified KFold는 이런 문제를 해결해줍니다.\n",
        "* 이번에는 Stratified KFold를 사용해봅시다.\n",
        "* 사용 방법은 KFold와 거의 비슷하지만, split() 인자에 레이블 데이터셋을 추가해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M7TFggulJ4Y",
        "outputId": "4c8b2276-84ed-44f6-eebf-1c60c82dc484"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(f\"## 교차 검증 : {n_iter}\")\n",
        "    print(f\"학습 레이블 데이터 분포 : \\n{label_train.value_counts()}\")\n",
        "    print(f\"검증 레이블 데이터 분포 : \\n{label_test.value_counts()}\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증 : 1\n",
            "학습 레이블 데이터 분포 : \n",
            "2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "\n",
            "## 교차 검증 : 2\n",
            "학습 레이블 데이터 분포 : \n",
            "1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "\n",
            "## 교차 검증 : 3\n",
            "학습 레이블 데이터 분포 : \n",
            "0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            "2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8oD_Cb3m_-d"
      },
      "source": [
        "* 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당되었습니다.\n",
        "* 이제 StratifiedKFold를 이용해 붓꽃 데이터를 교차 검증해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d5NOzt-mr3J",
        "outputId": "d5114efb-5a50-456a-a82e-cee2aea333c9"
      },
      "source": [
        "df_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "# split() 호출 시 반드시 레이블 데이터셋 추가 입력\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "    \n",
        "    # split()으로 반환된 인덱스를 이용해 학습용/검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    # 반복할 때마다 정확도 측정\n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print(f\"\\n#{n_iter} 교차 검증 정확도 : {accuracy}, \\\n",
        "    학습 데이터 크기 : {train_size}, \\\n",
        "    검증 데이터 크기 : {test_size}\")\n",
        "    print(f\"#{n_iter} 검증셋 인덱스 : {test_index}\")\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "# 교차 검증별 정확도 및 평균 정확도 계산\n",
        "print(f\"\\n## 교차 검증별 정확도 : {np.round(cv_accuracy, 4)}\")\n",
        "print(f\"\\n## 평균 검증 정확도 : {np.mean(cv_accuracy):.4f}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 0.98,     학습 데이터 크기 : 100,     검증 데이터 크기 : 50\n",
            "#1 검증셋 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "#2 교차 검증 정확도 : 0.92,     학습 데이터 크기 : 100,     검증 데이터 크기 : 50\n",
            "#2 검증셋 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.98,     학습 데이터 크기 : 100,     검증 데이터 크기 : 50\n",
            "#3 검증셋 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증별 정확도 : [0.98 0.92 0.98]\n",
            "\n",
            "## 평균 검증 정확도 : 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfO5LYrGo8pM"
      },
      "source": [
        "* 일반적으로 분류에서의 교차 검증은 Stratified K-fold로 분할되어야 합니다.\n",
        "* 회귀에서는 결정값이 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93v9YVJiorUn"
      },
      "source": [
        "### 4.2.3 cross_val_score()\n",
        "\n",
        "* 주요 파라미터\n",
        "    * `estimator` : Classifier or Regressor\n",
        "    * `X` : feature data set\n",
        "    * `y=None` : label data set\n",
        "    * `scoring=None` : 예측 성능 평가 지표\n",
        "    * `cv=None` : 교차 검증 폴드 수\n",
        "\n",
        "* 기타 파라미터\n",
        "    * `n_jobs=1`\n",
        "    * `verbose=0`\n",
        "    * `fit_params=None`\n",
        "    * `pre_dispatch='2*n_jobs'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3jDq3mzpVGD",
        "outputId": "fa4d0210-5c0c-4871-88ad-9c77ca546079"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "import numpy as np\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy), 교차 검증셋은 3개\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print(f\"교차 검증별 정확도 : {np.round(scores, 4)}\")\n",
        "print(f\"평균 검증 정확도 : {np.round(np.mean(scores), 4)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증별 정확도 : [0.98 0.94 0.98]\n",
            "평균 검증 정확도 : 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB4MqHai1yNM"
      },
      "source": [
        "* `cross_val_score()` API는 내부에서 estimator를 학습(fit), 예측(predict), 평가(evaluation)시켜주므로 간단하게 교차 검증을 수행할 수 있습니다.\n",
        "* `cross_val_score()`는 내부적으로 Stratified K-fold를 이용합니다.\n",
        "* 비슷한 API로 `cross_validate()`가 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oi2ID0JqNuW"
      },
      "source": [
        "## 4.3 Grid Search Cross Validation\n",
        "\n",
        "* 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에!!\n",
        "* Grid는 \"격자\"라는 뜻으로, 파라미터를 촘촘하게 입력하면서 테스트하는 방식입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_AuuKyw2khK",
        "outputId": "bf8c5857-bf91-4e21-d872-e7755cab93da"
      },
      "source": [
        "# decision tree algorithm's optimal hyper parameter\n",
        "grid_parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}\n",
        "grid_parameters"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCWmIhp3zgC"
      },
      "source": [
        "* depth 1 --> 2, 3\n",
        "* depth 2 --> 2, 3\n",
        "* depth 3 --> 2, 3\n",
        "    - 총 6회에 걸쳐 파라미터를 순차적으로 바꿔 실행하면서 최적의 파라미터와 수행 결과를 도출합니다.\n",
        "    - 시간이 오래 걸립니다.\n",
        "    - cv=3 이라면 총 3 x 6 = 18회의 학습/평가가 수행됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRwN4tQd3leh"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris_data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, \n",
        "                                                    iris_data.target, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "# 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IfRrvlH5HUY"
      },
      "source": [
        "* GridSearchCV 주요 생성자\n",
        "    * `estimator` : Classifier, Regressor, Pipeline\n",
        "    * `param_grid` : \"key + 리스트값\"을 가지는 딕셔너리가 주어집니다.\n",
        "        - estimator 튜닝을 위해 파라미터명과 사용될 여러 파라미터값을 지정합니다.\n",
        "    * `scoring` : 보통 문자열('accuracy')로 지정하나 별도의 함수도 지정할 수 있습니다.\n",
        "    * `cv`\n",
        "    * `refit=True` : True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 후 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXtPZWvt5GMZ",
        "outputId": "d0b54df2-82e9-4c45-e80e-526454d944b9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행\n",
        "# refit=True(default) : 가장 좋은 파라미터 설정으로 재학습\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid 하이퍼 파라미터를 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "grid_dtree.cv_results_"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.00143758, 0.00091497, 0.00072885, 0.00052786, 0.00051824,\n",
              "        0.00050831]),\n",
              " 'mean_score_time': array([0.00075587, 0.00057991, 0.00037225, 0.00032401, 0.00035961,\n",
              "        0.00035429]),\n",
              " 'mean_test_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.975     ,\n",
              "        0.975     ]),\n",
              " 'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'max_depth': 1, 'min_samples_split': 2},\n",
              "  {'max_depth': 1, 'min_samples_split': 3},\n",
              "  {'max_depth': 2, 'min_samples_split': 2},\n",
              "  {'max_depth': 2, 'min_samples_split': 3},\n",
              "  {'max_depth': 3, 'min_samples_split': 2},\n",
              "  {'max_depth': 3, 'min_samples_split': 3}],\n",
              " 'rank_test_score': array([5, 5, 3, 3, 1, 1], dtype=int32),\n",
              " 'split0_test_score': array([0.7  , 0.7  , 0.925, 0.925, 0.975, 0.975]),\n",
              " 'split1_test_score': array([0.7, 0.7, 1. , 1. , 1. , 1. ]),\n",
              " 'split2_test_score': array([0.7 , 0.7 , 0.95, 0.95, 0.95, 0.95]),\n",
              " 'std_fit_time': array([3.34964236e-04, 2.76785819e-04, 2.49358100e-04, 4.91678229e-05,\n",
              "        6.17304127e-05, 2.54047275e-05]),\n",
              " 'std_score_time': array([1.13136978e-04, 1.44738777e-04, 5.41143068e-05, 6.96737251e-06,\n",
              "        8.45480675e-06, 1.60822124e-05]),\n",
              " 'std_test_score': array([1.11022302e-16, 1.11022302e-16, 3.11804782e-02, 3.11804782e-02,\n",
              "        2.04124145e-02, 2.04124145e-02])}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhV60oLQ_Hcy"
      },
      "source": [
        "* `cv_result_` : `fit()` 수행 후 학습 데이터를 폴딩셋으로 분할하여 `param_grid`에 기술된 하이퍼 \n",
        "파라미터를 순차적으로 변경하면서 학습/평가를 수행하고 그 결과를 `cv_result_`\n",
        "속성에 기록합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "nLaD8RmU-sWg",
        "outputId": "0a66b975-6a75-4635-ec29-aeee11eeec67"
      },
      "source": [
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', \n",
        "           'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckOBAC7q8Pyx"
      },
      "source": [
        "* params : 수행할 때마다 적용된 하이퍼 파라미터값입니다.\n",
        "* mean_test_score : 개별 하이퍼 파라미터별로 폴딩 테스트셋에 대해 총 수행한 평가 평균값입니다.\n",
        "* rank_test_score : 하이퍼 파라미터별로 성능이 좋은 순위입니다. 1일 때 가장 최적의 하이퍼 파라미터입니다.\n",
        "* split[i]_test_score : cv 값으로 생성된 각각의 폴딩셋(cv=3 --> 3개의 폴딩셋)입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QzB3QEp79MQ",
        "outputId": "728c43ce-9e2c-4013-ef07-32d239429ae3"
      },
      "source": [
        "print(f\"Grid Search CV 최적 파라미터 : {grid_dtree.best_params_}\")\n",
        "print(f\"Grid Search CV 최고 정확도 : {grid_dtree.best_score_:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search CV 최적 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
            "Grid Search CV 최고 정확도 : 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAakOc20_aKn"
      },
      "source": [
        "* `best_params_` : `fit()` 수행 후 최고 성능의 하이퍼 파라미터값을 `best_params_` 속성에 기록합니다.\n",
        "* `best_score_` : `fit()` 수행 후 최고 성능의 하이퍼 파라미터값의 평가 결과값을 `best_score_` 속성에 기록합니다.\n",
        "    - (즉, `cv_result_`의 `rank_test_score=1`일 때의 값입니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3-T9e2SATK_",
        "outputId": "36a14925-8591-4123-e520-48636c305538"
      },
      "source": [
        "# Grid Search CV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# Grid Search CV의 best_estimator_는 이미 최적 학습이 되어 별도 학습이 필요 없음\n",
        "pred = estimator.predict(X_test)\n",
        "print(f\"Test data set's accuracy : {accuracy_score(y_test, pred):.4f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data set's accuracy : 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpezGwORBeOs"
      },
      "source": [
        "* `best_estimator_` : `refit=True`이면 GridSearchCV가 최적 성능의 하이퍼 파라미터로 Estimator를 학습하여 `best_esimator_`로 저장합니다."
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chap3_1_Accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOdTkTmYFsmli9DkEzpr0Ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyBlin/Study/blob/main/PyML/Chapter3_Evaluation/Chap3_1_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbELZVRZ2H9D"
      },
      "source": [
        "* 분류의 성능 평가 지표( Evaluation Metric )\n",
        ">* 정확도( Accuracy )\n",
        ">* 오차행렬( Confusion Matrix )\n",
        ">* 정밀도( Precision )\n",
        ">* 재현율( Recall )\n",
        ">* F1 Score\n",
        ">* ROC-AUC( Receiver Operating Characteristic - Area Under the Curve )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4pSRWAe3HX2"
      },
      "source": [
        "* 타이타닉 ML 알고리즘의 예측 정확도가 보통 80%대였습니다.\n",
        "* 하지만, 여자인 경우에 생존률이 높았기 때문에 무조건 여자만 생존으로 예측해도 결과는 비슷하게 나올 수 있습니다.\n",
        "* 그저 성별 조건 하나만으로 결정하는 별거 아닌 알고리즘도 높은 정확도를 나타내는 상황이 발생하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEjU3tK_WDeC"
      },
      "source": [
        "# 1.Accuracy\n",
        "\n",
        "* acc = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7B14L3m5ol"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "    # fit() 메서드는 아무것도 학습하지 않음\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    \n",
        "    # predict() : Sex==1 --> 0, Sex!=1 --> 0\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros((X.shape[0], 1))\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else:\n",
        "                pred[i] = 1\n",
        "        return pred"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdKc-Wxf4Fyk"
      },
      "source": [
        "* BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별만으로 생존자를 예측하는 단순 Classifier를 생성합니다.\n",
        "* Chapter2에서 설정했던 transform_features()을 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCDvTNjRtcz3"
      },
      "source": [
        "# transform_features() 생성\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "def titanic_fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# ML 알고리즘에 불필요한 속성 제거\n",
        "def titanic_drop(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# label encoding\n",
        "def titanic_le(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# 위에서 설정한 데이터 전처리 함수 종합\n",
        "def transform_features(df):\n",
        "    df = titanic_fillna(df)\n",
        "    df = titanic_drop(df)\n",
        "    df = titanic_le(df)\n",
        "    return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSz4oBnJodZL",
        "outputId": "97dc2757-718e-4f20-8eca-7494275660c0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 원본 데이터 로딩, 데이터 가공, 학습/테스트 데이터 분할\n",
        "titanic_df = pd.read_csv('./train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "# transform_features() 설정 필요\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=0)\n",
        "\n",
        "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "mypred = myclf.predict(X_test)\n",
        "print(f\"Dummy Classifier's accuracy : {accuracy_score(y_test, mypred):.4f}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy Classifier's accuracy : 0.7877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKX9eWtQqJpb"
      },
      "source": [
        "* 위와 같은 단순한 알고리즘으로 예측을 해도 정확도가 78.77%로 꽤 높게 나옵니다.\n",
        "* 그래서 정확도를 평가 지표로 사용할 때는 매우 신중해야 합니다.\n",
        "* 이제 MNIST 데이터셋의 '7'만 True로 하여 나머지를 0으로 예측해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUf7HzCD2E1m"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "    def fit(self, X, y):\n",
        "        pass\n",
        "\n",
        "    # 입력으로 들어오는 X 데이터셋의 크기만큼 모두 0값으로 변환\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "# 사이킷런 내장 데이터셋을 이용해 MNIST 데이터 로딩\n",
        "digits = load_digits()\n",
        "\n",
        "# digits '7'이면 True, astype(int) --> 1, 나머지 0\n",
        "y = (digits.target==7).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, \n",
        "                                                    random_state=11)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-acsBuzk845y"
      },
      "source": [
        "* 즉, False(0)가 90% 이므로 단순하게만 예측해도 결과는 90%입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YWD5M9x6nH2",
        "outputId": "8c987ba0-d550-4d20-b5ea-67287223366c"
      },
      "source": [
        "# 불균형한 레이블 데이터 분포도 확인\n",
        "print(f\"레이블 테스트셋 크기 : {y_test.shape}\")\n",
        "print(f\"\\n테스트셋 레이블 0과 1의 분포도 : \\n{pd.Series(y_test).value_counts()}\")\n",
        "\n",
        "# Dummy Classifier로 학습/예측/정확도 평가\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train, y_train)\n",
        "fakepred = fakeclf.predict(X_test)\n",
        "print(f\"\\n모두 0으로 예측한 정확도 : {accuracy_score(y_test, fakepred):.4f}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블 테스트셋 크기 : (450,)\n",
            "\n",
            "테스트셋 레이블 0과 1의 분포도 : \n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "\n",
            "모두 0으로 예측한 정확도 : 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuCmQVGh9xNl"
      },
      "source": [
        "* 이런 단순 예측이 ML 알고리즘과 맞설 수 있다는 것은 말도 안됩니다.\n",
        "* 이처럼 정확도 평가 지표는 불균형한 레이블 데이터셋에서는 성능 수치로 사용돼서는 안됩니다.\n",
        "* 여러 가지 분류 지표와 함께 적용해야 합니다."
      ]
    }
  ]
}